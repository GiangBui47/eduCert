from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage, trim_messages
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode
from src.tool.product_search import course_search_tool
from src.tool.policy_search import policy_search_tool
from langchain_groq import ChatGroq

import os 
from dotenv import load_dotenv
load_dotenv()


class ShoppingAgent:
    def __init__(self, llm, max_tokens: int = 2000, verbose: bool = False):
        """
        Agent with 2 tools:
          - course_search_tool
          - policy_search_tool
        """
        self.llm = llm
        self.max_tokens = max_tokens
        self.verbose = verbose

        self.tools = [course_search_tool, policy_search_tool]
        
        # âœ… FIX: KhÃ´ng dÃ¹ng tool_choice, Ä‘á»ƒ model tá»± quyáº¿t Ä‘á»‹nh
        self.llm_with_tools = llm.bind_tools(self.tools)

        self.graph = self._build_graph()

    def _build_graph(self):
        # âœ… FIX: System prompt rÃµ rÃ ng hÆ¡n, hÆ°á»›ng dáº«n cÃ¡ch dÃ¹ng tool
        system_prompt = (
            "Báº¡n lÃ  trá»£ lÃ½ AI thÃ´ng minh cho ná»n táº£ng há»c trá»±c tuyáº¿n LMS.\n"
            "Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vá» khÃ³a há»c vÃ  chÃ­nh sÃ¡ch.\n\n"
            "HÆ¯á»šNG DáºªN QUAN TRá»ŒNG:\n"
            "- Khi ngÆ°á»i dÃ¹ng há»i vá» KHÃ“A Há»ŒC, BÃ€I GIáº¢NG, CHÆ¯Æ NG Há»ŒC â†’ dÃ¹ng course_search_tool\n"
            "- Khi ngÆ°á»i dÃ¹ng há»i vá» CHÃNH SÃCH, ÄÄ‚NG KÃ, THANH TOÃN â†’ dÃ¹ng policy_search_tool\n"
            "- LuÃ´n tráº£ lá»i báº±ng tiáº¿ng Viá»‡t\n"
            "- ThÃ¢n thiá»‡n vÃ  cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c\n\n"
            "CÃ´ng cá»¥ cÃ³ sáºµn:\n"
            "1. course_search_tool(query: str) - TÃ¬m kiáº¿m khÃ³a há»c\n"
            "2. policy_search_tool(query: str) - TÃ¬m kiáº¿m chÃ­nh sÃ¡ch\n"
        )

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="messages"),
        ])

        trimmer = trim_messages(
            max_tokens=self.max_tokens,
            strategy="last",
            token_counter=self.llm,
            include_system=True,
        )

        def agent_node(state: MessagesState):
            """Node xá»­ lÃ½ chÃ­nh"""
            try:
                trimmed = trimmer.invoke(state["messages"])
                chain = prompt | self.llm_with_tools
                response = chain.invoke({"messages": trimmed})

                if self.verbose:
                    print(f"\n[Agent] Response content: {response.content}")
                    if hasattr(response, "tool_calls") and response.tool_calls:
                        print(f"[Agent] Tool calls: {response.tool_calls}")

                return {"messages": [response]}
            
            except Exception as e:
                if self.verbose:
                    print(f"\n[Agent ERROR] {type(e).__name__}: {str(e)}")
                
                # Tráº£ vá» error message thay vÃ¬ crash
                error_response = AIMessage(
                    content=f"Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i khi xá»­ lÃ½ yÃªu cáº§u cá»§a báº¡n. Vui lÃ²ng thá»­ láº¡i."
                )
                return {"messages": [error_response]}

        def route_to_tool_or_end(state: MessagesState) -> str:
            """Quyáº¿t Ä‘á»‹nh cÃ³ gá»i tool hay káº¿t thÃºc"""
            last = state["messages"][-1]
            if isinstance(last, AIMessage) and getattr(last, "tool_calls", None):
                if self.verbose:
                    print(f"[Router] Routing to TOOLS")
                return "tools"
            if self.verbose:
                print(f"[Router] Routing to END")
            return END

        tool_node = ToolNode(self.tools)

        graph_builder = StateGraph(MessagesState)
        graph_builder.add_node("agent", agent_node)
        graph_builder.add_node("tools", tool_node)

        graph_builder.add_edge(START, "agent")
        graph_builder.add_conditional_edges("agent", route_to_tool_or_end)
        graph_builder.add_edge("tools", "agent")

        memory = MemorySaver()
        return graph_builder.compile(checkpointer=memory)

    def invoke(self, query: str, session_id: str = "default") -> str:
        """Gá»i agent vá»›i query"""
        config = {"configurable": {"thread_id": session_id}}
        
        if self.verbose:
            print(f"\n{'='*70}")
            print(f"[Shopping Agent] User Query: {query}")
            print(f"{'='*70}")
        
        try:
            response = self.graph.invoke(
                {"messages": [HumanMessage(content=query)]}, 
                config
            )
            last_message = response["messages"][-1]

            if self.verbose:
                print(f"\n[Shopping Agent] âœ… Final Response:")
                print(f"{last_message.content}")
                print(f"{'='*70}\n")

            return last_message.content
        
        except Exception as e:
            error_msg = f"Lá»—i há»‡ thá»‘ng: {str(e)}"
            if self.verbose:
                print(f"\n[Shopping Agent] âŒ ERROR: {error_msg}\n")
            return f"Xin lá»—i, há»‡ thá»‘ng gáº·p lá»—i: {str(e)}"


if __name__ == "__main__":
    
    print("\nğŸ”§ Äang khá»Ÿi táº¡o Shopping Agent...")
    print("ğŸ“Œ Model: llama-3.3-70b-versatile")
    print("ğŸ“Œ Temperature: 0 (Ä‘á»ƒ tool calling á»•n Ä‘á»‹nh)\n")
    
    llm = ChatGroq(
        temperature=0,  
        model="llama-3.3-70b-versatile",  
        api_key=os.getenv("GROK_API_KEY")
    )

    shopping_agent = ShoppingAgent(llm, verbose=True)
    session_id = "session_demo_001"

    # Test 1: TÃ¬m khÃ³a há»c
    print("\n" + "ğŸ¯" * 30)
    print("TEST 1: TÃ¬m khÃ³a há»c Python")
    print("ğŸ¯" * 30)
    response1 = shopping_agent.invoke(
        "TÃ´i muá»‘n tÃ¬m khÃ³a há»c vá» láº­p trÃ¬nh Python cÆ¡ báº£n.",
        session_id
    )

    # Test 2: Há»i chÃ­nh sÃ¡ch
    print("\n" + "ğŸ¯" * 30)
    print("TEST 2: Há»i vá» chÃ­nh sÃ¡ch")
    print("ğŸ¯" * 30)
    response2 = shopping_agent.invoke(
        "LÃ m sao Ä‘á»ƒ táº¡o tÃ i khoáº£n há»c viÃªn má»›i?",
        session_id
    )


    print("\n" + "ğŸ¯" * 30)
    print("TEST 3: CÃ¢u há»i ná»‘i tiáº¿p")
    print("ğŸ¯" * 30)
    response3 = shopping_agent.invoke(
        "NgoÃ i Python thÃ¬ cÃ³ khÃ³a há»c nÃ o vá» Java khÃ´ng?",
        session_id
    )

    print("\nâœ… HoÃ n thÃ nh táº¥t cáº£ cÃ¡c test!")