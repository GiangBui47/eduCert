import os 
import numpy as np
from src.utils.embedding import generate_embeddings, get_embedding_model
from sklearn.metrics.pairwise import cosine_similarity


COURSE_SAMPLE = [
    "kh√≥a h·ªçc n√†y h·ªçc ph√≠ bao nhi√™u", 
    "kh√≥a h·ªçc n√†y k√©o d√†i bao l√¢u", 
    "khai gi·∫£ng kh√≥a h·ªçc ti·∫øp theo l√† khi n√†o", 
    "kh√≥a h·ªçc n√†y c√≥ c·∫•p ch·ª©ng ch·ªâ kh√¥ng", 
    "t√¥i c·∫ßn tr√¨nh ƒë·ªô g√¨ ƒë·ªÉ tham gia kh√≥a n√†y", 
    "h·ªçc online hay ph·∫£i ƒë·∫øn trung t√¢m", 
    "c√≥ h·ªó tr·ª£ h·ªçc vi√™n sau kh√≥a h·ªçc kh√¥ng", 
    "t√¥i c√≥ th·ªÉ h·ªçc th·ª≠ tr∆∞·ªõc kh√¥ng", 
    "c√≥ ∆∞u ƒë√£i gi·∫£m gi√° cho h·ªçc vi√™n m·ªõi kh√¥ng", 
    "t√¥i c√≥ th·ªÉ ho√†n ti·ªÅn n·∫øu kh√¥ng h√†i l√≤ng kh√¥ng",
    "kh√≥a h·ªçc n√†y c√≥ th·ª±c h√†nh kh√¥ng", 
    "h·ªçc ph√≠ ƒë√£ bao g·ªìm t√†i li·ªáu ch∆∞a", 
    "kh√≥a h·ªçc n√†y c√≥ h·ªó tr·ª£ t√¨m vi·ªác sau khi h·ªçc xong kh√¥ng", 
    "kh√≥a h·ªçc n√†y d√†nh cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu hay n√¢ng cao", 
    "gi√°o vi√™n c·ªßa kh√≥a n√†y l√† ai", 
    "c√≥ l·ªõp h·ªçc bu·ªïi t·ªëi kh√¥ng", 
    "c√≥ th·ªÉ h·ªçc tr√™n ƒëi·ªán tho·∫°i kh√¥ng", 
    "kh√≥a h·ªçc n√†y c√≥ bao nhi√™u b√†i gi·∫£ng", 
    "t√¥i c√≥ th·ªÉ h·ªçc l·∫°i b√†i ƒë√£ h·ªçc kh√¥ng", 
    "trung t√¢m c√≥ h·ªó tr·ª£ tr·∫£ g√≥p h·ªçc ph√≠ kh√¥ng", 
    "t√¥i c√≥ th·ªÉ ƒëƒÉng k√Ω nhi·ªÅu kh√≥a c√πng l√∫c kh√¥ng", 
    "n·∫øu t√¥i b·∫≠n th√¨ c√≥ th·ªÉ d·ªùi l·ªãch h·ªçc kh√¥ng", 
    "trung t√¢m c√≥ t·ªï ch·ª©c ki·ªÉm tra ƒë·∫ßu v√†o kh√¥ng", 
    "k·∫øt th√∫c kh√≥a h·ªçc c√≥ thi kh√¥ng", 
    "t√¥i c√≥ th·ªÉ chuy·ªÉn sang kh√≥a kh√°c n·∫øu mu·ªën kh√¥ng", 
    "trung t√¢m c√≥ ch∆∞∆°ng tr√¨nh h·ªçc cho tr·∫ª em kh√¥ng", 
    "kh√≥a h·ªçc c√≥ d·∫°y k·ªπ nƒÉng m·ªÅm kh√¥ng", 
    "t√¥i mu·ªën h·ªçc ƒë·ªÉ ƒëi du h·ªçc, n√™n ch·ªçn kh√≥a n√†o", 
    "h·ªçc xong kh√≥a n√†y c√≥ th·ªÉ ƒëi l√†m kh√¥ng", 
    "c√≥ h·ªó tr·ª£ CV hay ph·ªèng v·∫•n xin vi·ªác kh√¥ng", 
    "t√¥i mu·ªën h·ªçc l·∫≠p tr√¨nh, n√™n b·∫Øt ƒë·∫ßu t·ª´ kh√≥a n√†o", 
    "trung t√¢m c√≥ kh√≥a h·ªçc theo y√™u c·∫ßu ri√™ng kh√¥ng", 
    "c√≥ ch∆∞∆°ng tr√¨nh mentor h·ªó tr·ª£ kh√¥ng", 
    "h·ªçc online c√≥ t∆∞∆°ng t√°c v·ªõi gi·∫£ng vi√™n kh√¥ng", 
    "trung t√¢m c√≥ c∆° s·ªü ·ªü th√†nh ph·ªë n√†o", 
    "kh√≥a h·ªçc n√†y c√≥ ph√π h·ª£p v·ªõi ng∆∞·ªùi ƒëi l√†m kh√¥ng", 
    "n·∫øu t√¥i kh√¥ng c√≥ n·ªÅn t·∫£ng th√¨ h·ªçc ƒë∆∞·ª£c kh√¥ng", 
    "t√¥i c·∫ßn chu·∫©n b·ªã g√¨ tr∆∞·ªõc khi tham gia kh√≥a h·ªçc", 
    "c√≥ c·∫•p ch·ª©ng ch·ªâ qu·ªëc t·∫ø kh√¥ng"
]


CHITCHAT_SAMPLE = [
    "b·∫°n c√≥ hay h·ªçc online kh√¥ng", 
    "b·∫°n th√≠ch m√¥n h·ªçc n√†o nh·∫•t", 
    "tr·ªùi h√¥m nay ƒë·∫πp qu√° nh·ªâ", 
    "n√≥i chuy·ªán b·∫±ng ti·∫øng Vi·ªát ƒëi nh√©", 
    "b·∫°n c√≥ ƒëang l√†m vi·ªác ·ªü trung t√¢m kh√¥ng", 
    "b·∫°n c√≥ s·ªü th√≠ch g√¨ kh√¥ng", 
    "b·∫°n nghƒ© tr√≠ tu·ªá nh√¢n t·∫°o c√≥ th·ªÉ thay th·∫ø gi√°o vi√™n kh√¥ng", 
    "k·ªÉ t√¥i nghe m·ªôt c√¢u chuy·ªán vui ƒëi", 
    "b·∫°n c√≥ hay ƒë·ªçc s√°ch kh√¥ng", 
    "b·∫°n tin v√†o v·∫≠n may ch·ª©", 
    "n·∫øu ƒë∆∞·ª£c ƒëi du l·ªãch, b·∫°n mu·ªën ƒëi ƒë√¢u nh·∫•t", 
    "b·∫°n nghƒ© h·ªçc l√† ƒë·ªÉ l√†m g√¨", 
    "b·∫°n c√≥ nu√¥i th√∫ c∆∞ng kh√¥ng", 
    "b·∫°n th√≠ch nghe nh·∫°c lo·∫°i n√†o", 
    "n·∫øu c√≥ si√™u nƒÉng l·ª±c, b·∫°n mu·ªën c√≥ kh·∫£ nƒÉng g√¨", 
    "b·∫°n t·ª´ng nh·∫≠n ƒë∆∞·ª£c l·ªùi khuy√™n hay n√†o nh·∫•t", 
    "h√¥m nay c·ªßa b·∫°n th·∫ø n√†o", 
    "b·∫°n c√≥ hay m∆° khi ng·ªß kh√¥ng", 
    "b·∫°n th√≠ch m√πa n√†o nh·∫•t trong nƒÉm", 
    "n·∫øu ƒë∆∞·ª£c g·∫∑p m·ªôt nh√¢n v·∫≠t l·ªãch s·ª≠, b·∫°n ch·ªçn ai", 
    "b·∫°n th√≠ch ng√†y l·ªÖ n√†o nh·∫•t", 
    "b·∫°n c√≥ tin v√†o t√¢m linh kh√¥ng", 
    "m·ªôt ng√†y ho√†n h·∫£o c·ªßa b·∫°n s·∫Ω nh∆∞ th·∫ø n√†o", 
    "n·∫øu ƒë∆∞·ª£c h·ªçc k·ªπ nƒÉng m·ªõi, b·∫°n mu·ªën h·ªçc g√¨", 
    "b·∫°n th√≠ch ƒÉn m√≥n g√¨ nh·∫•t", 
    "b·∫°n c√≥ s·ª£ ƒë·ªô cao kh√¥ng", 
    "tu·ªïi th∆° c·ªßa b·∫°n c√≥ k·ª∑ ni·ªám n√†o ƒë√°ng nh·ªõ kh√¥ng", 
    "n·∫øu ƒë∆∞·ª£c du h√†nh th·ªùi gian, b·∫°n mu·ªën ƒë·∫øn th·ªùi n√†o", 
    "b·∫°n th√≠ch xem th·ªÉ thao kh√¥ng", 
    "b·∫°n th√≠ch ƒëi bi·ªÉn hay ƒëi n√∫i", 
    "b·∫°n c√≥ hay ch∆°i game kh√¥ng", 
    "n·∫øu ƒë∆∞·ª£c ch·ªçn l√†m con v·∫≠t n√†o, b·∫°n ch·ªçn g√¨", 
    "b·∫°n th√≠ch h√°t b√†i n√†o nh·∫•t", 
    "b·∫°n tin v√†o t√¨nh y√™u s√©t ƒë√°nh kh√¥ng", 
    "b·∫°n th∆∞·ªùng l√†m g√¨ ƒë·ªÉ th∆∞ gi√£n", 
    "n·∫øu ƒë∆∞·ª£c ƒÉn t·ªëi v·ªõi ai ƒë√≥ n·ªïi ti·∫øng, b·∫°n ch·ªçn ai", 
    "b·∫°n th√≠ch kem v·ªã g√¨ nh·∫•t", 
    "b·∫°n c√≥ t√†i l·∫ª n√†o kh√¥ng", 
    "b·∫°n th√≠ch c√¢u n√≥i n√†o nh·∫•t", 
    "n·∫øu tr√∫ng s·ªë, b·∫°n s·∫Ω l√†m g√¨ ƒë·∫ßu ti√™n"
]

COURSE_EMB_PATH = "src/data/cache/course_embeddings.npy"
CHITCHAT_EMB_PATH = "src/data/cache/chitchat_embeddings.npy"

def cache_embeddings(samples, file_path: str, model):
    
    os.makedirs(os.path.dirname(file_path), exist_ok=True)

    if os.path.exists(file_path):
        print(f"Embeddings cache ƒë√£ t·ªìn t·∫°i: {file_path}")
        return np.load(file_path)

    print(f"ƒêang t·∫°o m·ªõi embeddings cache: {file_path}")
    embeddings = model.encode(
        samples,
        batch_size=32,
        convert_to_numpy=True,
        show_progress_bar=True
    ).astype(np.float32)

    np.save(file_path, embeddings)
    print(f"L∆∞u embeddings cache xong: {file_path}")
    return embeddings

def load_or_create_all_embeddings():
   
    model = get_embedding_model()

    course_embeddings = cache_embeddings(COURSE_SAMPLE, COURSE_EMB_PATH, model)
    chitchat_embeddings = cache_embeddings(CHITCHAT_SAMPLE, CHITCHAT_EMB_PATH, model)

    all_embeddings = np.vstack([course_embeddings, chitchat_embeddings])
    all_samples = COURSE_SAMPLE + CHITCHAT_SAMPLE
    all_labels = ["course"] * len(COURSE_SAMPLE) + ["chitchat"] * len(CHITCHAT_SAMPLE)

    print(f"T·ªïng s·ªë embeddings: {len(all_embeddings)} (course: {len(COURSE_SAMPLE)}, chitchat: {len(CHITCHAT_SAMPLE)})")

    return model, all_embeddings, all_labels, all_samples


def classify_query(query: str, model, embeddings, labels):
    query_emb = model.encode([query], convert_to_numpy=True)
    similarities = cosine_similarity(query_emb, embeddings)[0]
    best_idx = np.argmax(similarities)
    best_label = labels[best_idx]

    return best_label




if __name__ == "__main__":
    print("üöÄ Kh·ªüi t·∫°o embeddings...")
    model, embeddings, labels, samples = load_or_create_all_embeddings()

    print("\nü§ñ Chatbot ph√¢n lo·∫°i c√¢u h·ªèi:")
    while True:
        query = input("\nüó£  Ng∆∞·ªùi d√πng: ").strip()
        if query.lower() in ["exit", "quit", "tho√°t"]:
            print("üëã T·∫°m bi·ªát!")
            break

        label = classify_query(query, model, embeddings, labels)
        print(f"üëâ Lo·∫°i c√¢u h·ªèi: {label}")




